Just getting familiar with NLTK, chunking,chinking,tokenizing, corpora, text datasets.

Basic splitting of text & labeling of training, testing datasets.

This is how NLTK classifies words & tags them in a huge human rights corporus!

![screenshot_118](https://user-images.githubusercontent.com/4441068/47607626-bdf9f200-da3b-11e8-9bfb-34610e7cf040.png)
![screenshot_117](https://user-images.githubusercontent.com/4441068/47607628-be928880-da3b-11e8-9f03-49807654e323.png)
![screenshot_116](https://user-images.githubusercontent.com/4441068/47607629-be928880-da3b-11e8-89e8-ac1fcf3ffd81.png)
![screenshot_115](https://user-images.githubusercontent.com/4441068/47607630-be928880-da3b-11e8-80e1-902143b07866.png)

![screenshot_113](https://user-images.githubusercontent.com/4441068/47607632-bf2b1f00-da3b-11e8-9c38-82f9b5522141.png)
![screenshot_112](https://user-images.githubusercontent.com/4441068/47607633-bf2b1f00-da3b-11e8-98f7-81e25d09785e.png)
![screenshot_111](https://user-images.githubusercontent.com/4441068/47607634-bf2b1f00-da3b-11e8-8c99-23fe055fe8ac.png)
![screenshot_114](https://user-images.githubusercontent.com/4441068/47607637-cce0a480-da3b-11e8-92fc-65fd89ffbf4f.png)


